{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8307,
     "status": "ok",
     "timestamp": 1655650792101,
     "user": {
      "displayName": "김택완",
      "userId": "03512252637489286729"
     },
     "user_tz": -540
    },
    "id": "l2J1KrMnTqSx",
    "outputId": "5bc6878f-3a30-4c30-9e58-af8d58374cb9"
   },
   "outputs": [],
   "source": [
    "# !pip install torchcontrib\n",
    "# !pip install iterative-stratification\n",
    "# !pip install fastparquet\n",
    "# !pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1655688182155,
     "user": {
      "displayName": "김택완",
      "userId": "03512252637489286729"
     },
     "user_tz": -540
    },
    "id": "dd2JIecotCDW",
    "outputId": "1d2b61a7-68d1-44bc-cd18-b8e6beaa5a98"
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f_kcd3-xFplW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcontrib.optim import SWA\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import joblib\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RVNNAJpKTWrZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mXSMGb6Dcbzy"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "index = 0\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "data_dir = './bengaliai-cv19'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH783nzAVjd7"
   },
   "source": [
    "Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Zt-Q6GBTAUA"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'./{data_dir}/train.csv')\n",
    "files_train = [f'train_image_data_{fid}.parquet' for fid in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4Y7TqgpdsY5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "F = os.path.join(data_dir, files_train[0])\n",
    "\n",
    "train0 = pd.read_parquet(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1655648463735,
     "user": {
      "displayName": "김택완",
      "userId": "03512252637489286729"
     },
     "user_tz": -540
    },
    "id": "h55-QoHzVVQZ",
    "outputId": "0dde9834-d8ca-43c7-86c9-7b143259e022"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "img = train0.iloc[idx, 1:].values.astype(np.uint8)\n",
    "\n",
    "img.reshape(137, 236).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rQYxrOIfddM"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(train0))\n",
    "img = train0.iloc[idx, 1:].values.astype(np.uint8)\n",
    "img = 255 - img\n",
    "\n",
    "plt.imshow(img.reshape(137, 236), cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vc2-jUbUfdWv"
   },
   "outputs": [],
   "source": [
    "img_ids = train0['image_id'].values\n",
    "img_array = train0.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgEZavt7fdGx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !mkdir train_image\n",
    "\n",
    "img_id  = img_ids[idx]\n",
    "img = img_array[idx]\n",
    "\n",
    "joblib.dump(img, f'{data_dir}/train_image/{img_id}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJh4iFgQi3ih"
   },
   "outputs": [],
   "source": [
    "# data set memory를 효율적으로 쓰기위해 pandas가 아닌 array로 저장\n",
    "img_ids = df_train['image_id'].values\n",
    "tmp = 0\n",
    "for fname in (files_train):\n",
    "  F = os.path.join(data_dir, fname)\n",
    "  df_train = pd.read_parquet(F)\n",
    "  img_array = df_train.iloc[:,1:].values\n",
    "  for idx in tqdm(range(len(df_train))):\n",
    "    img_id = img_ids[tmp]\n",
    "    img = img_array[idx]\n",
    "    joblib.dump(img, f'{data_dir}/train_image/{img_id}.pkl')\n",
    "    tmp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-sGZVYPj47h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#저장한 dump파일을 하나씩 불러와서 학습하도록 만들어줌\n",
    "img_id = df_train['image_id'][0]\n",
    "img = joblib.load(f'{data_dir}/train_image/{img_id}.pkl').astype(np.uint8) #이미지는 0~255 int8로 해주는게 컴퓨팅 계산에 효율적\n",
    "\n",
    "img = img.reshape(HEIGHT, WIDTH)\n",
    "img[:,:, np.newaxis].shape # 채널을 하나 만들어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load(f'{data_dir}/train_image/{img_id}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFNBmD--Vr3K"
   },
   "source": [
    "# Splits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./bengaliai-cv19/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,20))\n",
    "df_train['consonant_diacritic'].value_counts().sort_index().plot.barh()  #data bias가 상당히 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5HzwD0mlWCX"
   },
   "outputs": [],
   "source": [
    "# 레이블 지정\n",
    "\n",
    "label_1 = df_train.iloc[index].grapheme_root\n",
    "label_2 = df_train.iloc[index].vowel_diacritic\n",
    "label_3 = df_train.iloc[index].consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5Ib4qXEVVIF"
   },
   "outputs": [],
   "source": [
    "df_train[\"id\"] = df_train['image_id'].apply(lambda x : int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dfk-EufUVVDb"
   },
   "outputs": [],
   "source": [
    "X = df_train[['id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values[:, 0]\n",
    "y = df_train[['id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v8vWsfaVUvP"
   },
   "outputs": [],
   "source": [
    "mskf = MultilabelStratifiedKFold(n_splits= 6, shuffle = True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alL8dKXvYyd8"
   },
   "outputs": [],
   "source": [
    "df_train['fold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6523,
     "status": "ok",
     "timestamp": 1655649641816,
     "user": {
      "displayName": "김택완",
      "userId": "03512252637489286729"
     },
     "user_tz": -540
    },
    "id": "S93u5COvY2Zk",
    "outputId": "227637c8-75a0-45f4-ea20-20a2578aa5f6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, (trn_idx, vid_idx) in enumerate(mskf.split(X,y)):\n",
    "  df_train.loc[vid_idx, 'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1655649641817,
     "user": {
      "displayName": "김택완",
      "userId": "03512252637489286729"
     },
     "user_tz": -540
    },
    "id": "V0tPAhMuZG1n",
    "outputId": "c25a9e9c-c4a8-47c1-ac0b-5305aa30825b"
   },
   "outputs": [],
   "source": [
    "df_train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQNk4UwUZGZR"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('./bengaliai-cv19/df_folds.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRyeIm3_bGqx"
   },
   "source": [
    "# Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xg3ag_RObIVk"
   },
   "outputs": [],
   "source": [
    "class BengaliDataset(Dataset):\n",
    "  def __init__(self, csv, img_height, img_width, transform):\n",
    "    self.csv = csv.reset_index()\n",
    "    self.img_ids = csv['image_id'].values\n",
    "    self.img_height = img_height\n",
    "    self.img_width = img_width\n",
    "    self.transform = transform\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.csv)\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_id = self.img_ids[index]\n",
    "    img = joblib.load(f'./{data_dir}/train_image/{img_id}.pkl')\n",
    "    img = img.reshape(self.img_height, self.img_width).astype(np.uint8)\n",
    "    img = (255 - img)/255\n",
    "    img = img[:,:, np.newaxis]\n",
    "\n",
    "    img = np.repeat(img, 3, 2)   #채널을 3으로 변경해줌\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img = self.transform(image = img)['image']\n",
    "\n",
    "    label_1 = self.csv.iloc[index].grapheme_root\n",
    "    label_2 = self.csv.iloc[index].vowel_diacritic\n",
    "    label_3 = self.csv.iloc[index].consonant_diacritic\n",
    "\n",
    "    return img, np.array([label_1, label_2, label_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPHGE4pzcKVX"
   },
   "source": [
    "# Define augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = A.Compose([\n",
    "    A.Rotate(20),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "vaild_aug = A.Compose([\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose([\n",
       "  Rotate(always_apply=False, p=0.5, limit=(-20, 20), interpolation=1, border_mode=4, value=None, mask_value=None),\n",
       "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
       "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200835</th>\n",
       "      <td>Train_200835</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>র্খে</td>\n",
       "      <td>200835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200836</th>\n",
       "      <td>Train_200836</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>ত্তো</td>\n",
       "      <td>200836</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200837</th>\n",
       "      <td>Train_200837</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>অ্যা</td>\n",
       "      <td>200837</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200838</th>\n",
       "      <td>Train_200838</td>\n",
       "      <td>152</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>স্নো</td>\n",
       "      <td>200838</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200839</th>\n",
       "      <td>Train_200839</td>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>ল্টি</td>\n",
       "      <td>200839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  grapheme_root  vowel_diacritic  consonant_diacritic  \\\n",
       "200835  Train_200835             22                7                    2   \n",
       "200836  Train_200836             65                9                    0   \n",
       "200837  Train_200837              2                1                    4   \n",
       "200838  Train_200838            152                9                    0   \n",
       "200839  Train_200839            127                2                    0   \n",
       "\n",
       "       grapheme      id  fold  \n",
       "200835     র্খে  200835     1  \n",
       "200836     ত্তো  200836     4  \n",
       "200837     অ্যা  200837     5  \n",
       "200838     স্নো  200838     4  \n",
       "200839     ল্টি  200839     4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./bengaliai-cv19/df_folds.csv')\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fold = [i for i in range(6) if i not in [5]]\n",
    "vld_fold = [5]\n",
    "trn_idx = df_train.loc[df_train['fold'].isin(trn_fold)].index\n",
    "vld_idx = df_train.loc[df_train['fold'].isin(vld_fold)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = BengaliDataset(csv = df_train.loc[trn_idx],\n",
    "                             img_height = HEIGHT,\n",
    "                             img_width = WIDTH,\n",
    "                             transform = train_aug)\n",
    "\n",
    "vld_dataset = BengaliDataset(csv = df_train.loc[vld_idx],\n",
    "                            img_height = HEIGHT,\n",
    "                            img_width = WIDTH,\n",
    "                            transform = vaild_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = DataLoader(trn_dataset,\n",
    "                       shuffle = True,\n",
    "#                        num_workers = 2,\n",
    "                       batch_size = 32,\n",
    "                       )\n",
    "\n",
    "vld_loader = DataLoader(vld_dataset,\n",
    "                       shuffle = False,\n",
    "#                        num_workers = 2,\n",
    "                       batch_size = 32,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae139b0f0c1a4bf2984adbbab72dea73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'shpae'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'shpae'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for inputs, targets in tqdm(trn_loader):\n",
    "    break\n",
    "    \n",
    "# def train():\n",
    "#   for inputs , targets in tqdm(trn_loader):\n",
    "#         break\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model, opt, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
     ]
    }
   ],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet34'\n",
    "model = pretrainedmodels.__dict__[model_name](pretrained = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features =  model.last_linear.in_features\n",
    "\n",
    "model.last_linear = nn.Linear(in_features, 186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      mode='max',\n",
    "                                                      verbose = True,\n",
    "                                                      factor = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): None\n",
       "  (last_linear): Linear(in_features=512, out_features=186, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = []\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8f678bcd4449238f220a1038f40f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(trn_loader):\n\u001b[0;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      3\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tqdm\\notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    556\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    559\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mBengaliDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     15\u001b[0m   img_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_ids[index]\n\u001b[1;32m---> 16\u001b[0m   img \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train_image/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimg_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m   img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_width)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     18\u001b[0m   img \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m-\u001b[39m img)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\joblib\\numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    577\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for inputs, targets in tqdm(trn_loader):\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "    \n",
    "    logits = model(inputs.float())\n",
    "    \n",
    "    \n",
    "    grapheme = logits[:, :168]\n",
    "    vowel = logits[:, 168:179]\n",
    "    cons = logits[:, 179:]\n",
    "    \n",
    "    \n",
    "    loss = (0.5 * loss_fn(grapheme, targets[:, 0])) + (0.25*loss_fn(vowel, targets[:, 1])) + (0.25*loss_fn(cons, targets[: , 2]))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0130352a044eb8bf6c43219ce5fed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1.39816; val_loss: 0.64982; score: 0.73888\n",
      "score_g : 0.66300; score_v: 0.81963; score_c: 0.80989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d96df6dc8742579c87233b8175895c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1.39816; val_loss: 0.64982; score: 0.73888\n",
      "score_g : 0.66300; score_v: 0.81963; score_c: 0.80989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38325e8bc06e4bdf82b11c15492d03ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1.39816; val_loss: 0.64982; score: 0.73888\n",
      "score_g : 0.66300; score_v: 0.81963; score_c: 0.80989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7305c47abf43e3b56a126bde512a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1.39816; val_loss: 0.64982; score: 0.73888\n",
      "score_g : 0.66300; score_v: 0.81963; score_c: 0.80989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e266e3d3ad3b4d099b3eae7ffa3b4ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m cons \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m179\u001b[39m:]\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m loss_fn(grapheme, targets[:, \u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mloss_fn(vowel, targets[:, \u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.25\u001b[39m\u001b[38;5;241m*\u001b[39mloss_fn(cons, targets[: , \u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m---> 25\u001b[0m val_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     27\u001b[0m grapheme \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(grapheme\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     28\u001b[0m vowel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(vowel\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    val_loss = []\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(vld_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            logits = model(inputs.float())\n",
    "\n",
    "\n",
    "            grapheme = logits[:, :168]\n",
    "            vowel = logits[:, 168:179]\n",
    "            cons = logits[:, 179:]\n",
    "\n",
    "\n",
    "            loss = (0.5 * loss_fn(grapheme, targets[:, 0])) + (0.25*loss_fn(vowel, targets[:, 1])) + (0.25*loss_fn(cons, targets[: , 2]))\n",
    "\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            grapheme = torch.nn.functional.softmax(grapheme.cpu(), dim=1).argmax(dim=1).data.numpy()\n",
    "            vowel = torch.nn.functional.softmax(vowel.cpu(), dim=1).argmax(dim=1).data.numpy()\n",
    "            cons = torch.nn.functional.softmax(cons.cpu(), dim=1).argmax(dim=1).data.numpy()\n",
    "\n",
    "            val_true.append(targets.cpu().numpy())\n",
    "            val_pred.append(np.stack([grapheme, vowel, cons], axis = 1))\n",
    "\n",
    "    val_true = np.concatenate(val_true)\n",
    "    val_pred = np.concatenate(val_pred)\n",
    "    val_loss = np.mean(val_loss) \n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    score_g = recall_score(val_true[:, 0], val_pred[:, 0], average='macro')\n",
    "    score_v = recall_score(val_true[:, 1], val_pred[:, 1], average='macro')\n",
    "    score_c = recall_score(val_true[:, 2], val_pred[:, 2], average='macro')\n",
    "    final_score = np.average([score_g,score_v, score_c], weights = [2,1,1])\n",
    "\n",
    "    print(f'train_loss : {train_loss:.5f}; val_loss: {val_loss:.5f}; score: {final_score:.5f}')\n",
    "    print(f'score_g : {score_g:.5f}; score_v: {score_v:.5f}; score_c: {score_c:.5f}')\n",
    "\n",
    "\n",
    "    if final_score > best_score:\n",
    "        best_score = final_score\n",
    "\n",
    "        state_dict = model.cpu().state_dict()\n",
    "        model = model.cuda()\n",
    "        torch.save(state_dict, \"test_model.pt\")\n",
    "        print('SAVE MODE UPDATE')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33474, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(val_true).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./test_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNx1oFvuGC3EU/kvGQw5HlK",
   "collapsed_sections": [],
   "mount_file_id": "1RT45Sa1EGDI0b7_rBZFsp52oZBwUey8e",
   "name": "Bengali_clf.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
