{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d4b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa079468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90889a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm.auto import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 256\n",
    "\n",
    "# Load dataset info\n",
    "path_to_train = '../test/human-protein-atlas-image-classification/train/'\n",
    "data = pd.read_csv('../test/human-protein-atlas-image-classification/train.csv')\n",
    "\n",
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c978e4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../test/human-protein-atlas-image-classification/train/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be622167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator:\n",
    "    \n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        while True:\n",
    "            dataset_info = shuffle(dataset_info)\n",
    "            for start in range(0, len(dataset_info), batch_size):\n",
    "                end = min(start + batch_size, len(dataset_info))\n",
    "                batch_images = []\n",
    "                X_train_batch = dataset_info[start:end]\n",
    "                batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = data_generator.load_image(\n",
    "                        X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "                    batch_images.append(image/255.)\n",
    "                    batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "                yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "        np.array(image_red_ch), \n",
    "        np.array(image_green_ch), \n",
    "        np.array(image_blue_ch)), -1)\n",
    "        image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "\n",
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=input_shape)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e74cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 4\n",
    "checkpoint = ModelCheckpoint('./working/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.0001) # epsilon instead 사용함\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.create_train(\n",
    "    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "validation_generator = data_generator.create_train(\n",
    "    train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be20cf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6422532526109727099\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 1751030171\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4728971078673903060\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ebc50c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb7dbf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.3591\n",
      "Epoch 00001: val_loss improved from inf to 0.15674, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 895s 135ms/step - loss: 0.1747 - accuracy: 0.3591 - val_loss: 0.1567 - val_accuracy: 0.4423 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.4408\n",
      "Epoch 00002: val_loss improved from 0.15674 to 0.15231, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 877s 133ms/step - loss: 0.1502 - accuracy: 0.4408 - val_loss: 0.1523 - val_accuracy: 0.4425 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.4938\n",
      "Epoch 00003: val_loss improved from 0.15231 to 0.12726, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 914s 138ms/step - loss: 0.1348 - accuracy: 0.4938 - val_loss: 0.1273 - val_accuracy: 0.5004 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.5235\n",
      "Epoch 00004: val_loss did not improve from 0.12726\n",
      "6603/6603 [==============================] - 892s 135ms/step - loss: 0.1262 - accuracy: 0.5235 - val_loss: 0.1325 - val_accuracy: 0.5211 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.5504\n",
      "Epoch 00005: val_loss improved from 0.12726 to 0.12318, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 900s 136ms/step - loss: 0.1193 - accuracy: 0.5504 - val_loss: 0.1232 - val_accuracy: 0.5468 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.5693\n",
      "Epoch 00006: val_loss did not improve from 0.12318\n",
      "6603/6603 [==============================] - 900s 136ms/step - loss: 0.1155 - accuracy: 0.5693 - val_loss: 0.1301 - val_accuracy: 0.5579 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.5782\n",
      "Epoch 00007: val_loss improved from 0.12318 to 0.12027, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 911s 138ms/step - loss: 0.1106 - accuracy: 0.5782 - val_loss: 0.1203 - val_accuracy: 0.5660 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.5915\n",
      "Epoch 00008: val_loss improved from 0.12027 to 0.11449, saving model to ./working\\InceptionV3.h5\n",
      "6603/6603 [==============================] - 888s 135ms/step - loss: 0.1066 - accuracy: 0.5915 - val_loss: 0.1145 - val_accuracy: 0.5888 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.5996\n",
      "Epoch 00009: val_loss did not improve from 0.11449\n",
      "6603/6603 [==============================] - 911s 138ms/step - loss: 0.1033 - accuracy: 0.5996 - val_loss: 0.1207 - val_accuracy: 0.5776 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "6603/6603 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.6046\n",
      "Epoch 00010: val_loss did not improve from 0.11449\n",
      "6603/6603 [==============================] - 910s 138ms/step - loss: 0.1006 - accuracy: 0.6046 - val_loss: 0.1236 - val_accuracy: 0.5191 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "#model create\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=28)\n",
    "\n",
    "\n",
    "# model fit\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d38c90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4875f6859cdc417992da70fa26c5befc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../test/human-protein-atlas-image-classification/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "model.load_weights('./working/InceptionV3.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../test/human-protein-atlas-image-classification/test/', name)\n",
    "    image = data_generator.load_image(path, (SIZE,SIZE,3))/255.\n",
    "    score_predict = model.predict(image[np.newaxis])[0]\n",
    "    draw_predict.append(score_predict)\n",
    "    label_predict = np.arange(28)[score_predict>=0.2]\n",
    "    str_predict_label = ' '.join(str(l) for l in label_predict)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "np.save('draw_predict_InceptionV3.npy', score_predict)\n",
    "submit.to_csv('submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5deca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
